---
title: "Homework 5"
author: "Paul Perez"
date: "3/14/2021"
output: html_document
subtitle: 'Forecasting: Principles and Practice - Exponential Smoothing'
---


```{r, warning=FALSE, results='hide', echo=FALSE, message=FALSE}
library(fpp2)
library(ggplot2)
```

# Exercise 7.8 - 1
Consider the `pigs` series - the number of pigs slaughtered in Victoria each month

## a. Use the ses() function in R to find the optimizal values of α and ℓ0, and generate forecasts for the next four months

```{r}
fc <- ses(pigs, h = 4)
fc
```

```{r}
autoplot(fc) +
  autolayer(fitted(fc), series="Fitted") +
  ylab("Number of Slaughtered Pigs in Victoria") + xlab("Year")
```


```{r}
fc$model
```

The optimal alpha is 0.2971 and the optimal l is 77260.0561.


## b. Compute a 95% prediction interval for the first forecast using  ^y ± 1.96s where s  is the standard deviation of the residuals. Compare your interval with the interval produced by R.

```{r}
s <- sd(fc$residuals)
high <- fc$mean+1.96*s
low <- fc$mean-1.96*s

high[[1]]
low[[1]]
```

Looking at the `Lo 95` and `Hi 95` from the R formula, 78611.97 and 119020.8 respectively, our manually calculated values, 78679.97 and 118952.8, are very close.

\newpage

# Exercise 7.8 - 5
Data set `books` contains the daily sales of paperback and hardcover books at the same store. The task is to forecast the next four days’ sales for paperback and hardcover books.

## a. Plot the series and discuss the main features of the data.

```{r}
autoplot(books)
```

Initially looking at the graph, we can see that paperback books tend to have peaks while the hardcover books are at their troughs. This is an upward trend.

## b. Use the ses() function to forecast each series, and plot the forecasts.

```{r}
fc_paper <- ses(books[,"Paperback"], h = 4)
fc_paper

autoplot(fc_paper) +
  autolayer(fitted(fc_paper), series="Fitted") +
  ylab("Paperback Books") + xlab("Time")
```


```{r}
fc_hard <- ses(books[,"Hardcover"], h = 4)
fc_hard

autoplot(fc_hard) +
  autolayer(fitted(fc_hard), series="Fitted") +
  ylab("Hardcover Books") + xlab("Time")
```


## c. Compute the RMSE values for the training data in each case.

```{r}
accuracy(fc_paper)[2]
accuracy(fc_hard)[2]
```

The RMSE for the paperback books is 33.63769 while the RMSE for the hardcover books is 31.93101.

\newpage

# Exercise 7.8 - 6
We will continue with the daily sales of paperback and hardcover books in data set `books`.

## a. Apply Holt’s linear method to the paperback and hardback series and compute four-day forecasts in each case.

```{r}
ht_paper <- holt(books[,"Paperback"], h = 4)
ht_paper

autoplot(ht_paper) +
  autolayer(fitted(ht_paper), series="Fitted") +
  ylab("Paperback Books") + xlab("Time")
```

```{r}
ht_hard <- holt(books[,"Hardcover"], h = 4)
ht_hard

autoplot(ht_hard) +
  autolayer(fitted(ht_hard), series="Fitted") +
  ylab("Paperback Books") + xlab("Time")

```

## b. Compare the RMSE measures of Holt’s method for the two series to those of simple exponential smoothing in the previous question. (Remember that Holt’s method is using one more parameter than SES.) Discuss the merits of the two forecasting methods for these data sets.

```{r}
accuracy(fc_paper)[2]
accuracy(fc_hard)[2]
accuracy(ht_paper)[2]
accuracy(ht_hard)[2]
```

While the RMSE for paperback and hardcover using simple expontial smoothing were 33.63769 and 31.93101 respectively, they were 31.13692 and 27.19358 using Holt's linear method. The charts above take into account trend and forecast off trend.

## c. Compare the forecasts for the two series using both methods. Which do you think is best?

Considering we just called out trend being accounted for using Holt's linear method, while also having lower RMSE's, we would want look to utilize Holt's as the better fit.


## d. Calculate a 95% prediction interval for the first forecast for each series, using the RMSE values and assuming normal errors. Compare your intervals with those produced using `ses` and `holt`.

### Simple Exponential Smoothing Intervals
```{r}
s <- sd(fc_paper$residuals)
high <- fc_paper$mean+1.96*s
low <- fc_paper$mean-1.96*s

high[[1]]
low[[1]]
```

```{r}
s <- sd(fc_hard$residuals)
high <- fc_hard$mean+1.96*s
low <- fc_hard$mean-1.96*s

high[[1]]
low[[1]]
```

### Holt's Linear Intervals

```{r}
s <- sd(ht_paper$residuals)
high <- ht_paper$mean+1.96*s
low <- ht_paper$mean-1.96*s

high[[1]]
low[[1]]
```

```{r}
s <- sd(ht_hard$residuals)
high <- ht_hard$mean+1.96*s
low <- ht_hard$mean-1.96*s

high[[1]]
low[[1]]
```

Comparing the simple exponential and holt linear intervals for the paperback books, the range in limits is greater in the simple exponential. The same case is applicable for the hardcover books as well. 

\newpage

# Exercise 7.8 - 7
For this exercise use data set `eggs`, the price of a dozen eggs in the United States from 1900–1993. Experiment with the various options in the `holt()` function to see how much the forecasts change with damped trend, or with a Box-Cox transformation. Try to develop an intuition of what each argument is doing to the forecasts.

[Hint: use `h=100` when calling `holt()` so you can clearly see the differences between the various options when plotting the forecasts.]

```{r}
ht_eggs1 <- holt(eggs, h = 100)
ht_eggs1

autoplot(ht_eggs1) +
  autolayer(fitted(ht_eggs1), series="Fitted") +
  ylab("Eggs") + xlab("Time")
```

```{r}
ht_eggs2 <- holt(eggs, damped = TRUE, h = 100)
ht_eggs2

autoplot(ht_eggs2) +
  autolayer(fitted(ht_eggs2), series="Fitted") +
  ylab("Eggs") + xlab("Time")
```

```{r}
ht_eggs3 <- holt(eggs, lambda = BoxCox.lambda(eggs), h = 100)
ht_eggs3

autoplot(ht_eggs3) +
  autolayer(fitted(ht_eggs3), series="Fitted") +
  ylab("Eggs") + xlab("Time")
```

```{r}
ht_eggs4 <- holt(eggs, lambda = BoxCox.lambda(eggs), damped = TRUE, h = 100) 
ht_eggs4

autoplot(ht_eggs4) +
  autolayer(fitted(ht_eggs4), series="Fitted") +
  ylab("Eggs") + xlab("Time")
```

```{r}
accuracy(ht_eggs1)[2]
accuracy(ht_eggs2)[2]
accuracy(ht_eggs3)[2]
accuracy(ht_eggs4)[2]
```


While all of them have very similar RMSE's, our third model using Holt's linear function while also applying a Box.Cox lamda transformation and setting h to 100 had the lowest RMSE.

\newpage

# Exercise 7.8 - 8
Recall your retail time series data (from Exercise 3 in Section 2.10).

## a. Why is multiplicative seasonality necessary for this series?

```{r}
retaildata <- readxl::read_excel("retail.xlsx", skip=1)

myts <- ts(retaildata[,"A3349414R"],
  frequency=12, start=c(1982,4))

autoplot(myts)
```

While there is clearly an uptrend in the data, there are a few years that do not look to be a gradual and consistent increase. It is almost exponential as the dot come bubble hits in the late 1990's, possibly related.

## b. Apply Holt-Winters’ multiplicative method to the data. Experiment with making the trend damped.

```{r}
ht_myts1 <- hw(myts, seasonal = "multiplicative", h = 100)
ht_myts1

autoplot(ht_myts1) +
  autolayer(fitted(ht_myts1), series="Fitted") +
  ylab("Liquor Sales") + xlab("Time")
```


```{r}
ht_myts2 <- hw(myts, seasonal = "multiplicative", damped = TRUE, h = 100)
ht_myts2

autoplot(ht_myts2) +
  autolayer(fitted(ht_myts2), series="Fitted") +
  ylab("Liquor Sales") + xlab("Time")
```

## c. Compare the RMSE of the one-step forecasts from the two methods. Which do you prefer?

```{r}
accuracy(ht_myts1)[2]
accuracy(ht_myts2)[2]
```

In this instance, unlike the last question, the dampened model yields a lower RMSE.

## d. Check that the residuals from the best method look like white noise.

```{r}
checkresiduals(ht_myts2)
```

There appear to be some outliers but are not concerning.

## e. Now find the test set RMSE, while training the model to the end of 2010. Can you beat the seasonal naïve approach from Exercise 8 in Section 3.7?


```{r}
myts.train <- window(myts, end=c(2010,12))
myts.test <- window(myts, start=2011)
```

```{r}
n_myts <- snaive(myts.train)
n_myts

autoplot(n_myts) +
  autolayer(fitted(n_myts), series="Fitted") +
  ylab("Liquor Sales") + xlab("Time")
```

```{r}
ht_myts3 <- hw(myts.train, seasonal = "multiplicative", damped = TRUE, h = 100)
ht_myts3

autoplot(ht_myts3) +
  autolayer(fitted(ht_myts3), series="Fitted") +
  ylab("Liquor Sales") + xlab("Time")
```

```{r}
accuracy(n_myts)[2]
accuracy(ht_myts3)[2]
```

The RMSE for the naive model produced a higher RMSE than the dampened model.
